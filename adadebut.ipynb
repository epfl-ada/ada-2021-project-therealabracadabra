{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bz2\n",
    "import json\n",
    "from urllib.parse import urlparse\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation d'un nouveau fichier avec une nouvelle colonne pour le domaine (cf colab)\n",
    "from tld import get_tld\n",
    "\n",
    "def get_domain(url):\n",
    "    res = get_tld(url, as_object=True)\n",
    "    return res.tld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pareil\n",
    "path_to_file = 'quotes-2020.json.bz2' \n",
    "path_to_out = 'quotes-2020-domains.json.bz2'\n",
    "\n",
    "with bz2.open(path_to_file, 'rb') as s_file:\n",
    "    with bz2.open(path_to_out, 'wb') as d_file:\n",
    "        for instance in s_file:\n",
    "            instance = json.loads(instance) # loading a sample\n",
    "            urls = instance['urls'] # extracting list of links\n",
    "            domains = []\n",
    "            for url in urls:\n",
    "                tld = get_domain(url)\n",
    "                domains.append(tld)\n",
    "            instance['domains'] = domains # updating the sample with domain name\n",
    "            d_file.write((json.dumps(instance)+'\\n').encode('utf-8')) # writing in the new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cette fois ci on rajoute une colonne avec simplement le nom du site\n",
    "path_to_file = 'quotes-2020-domains.json.bz2' \n",
    "path_to_out = '2020a.json.bz2'\n",
    "\n",
    "with bz2.open(path_to_file, 'rb') as s_file:\n",
    "    with bz2.open(path_to_out, 'wb') as d_file:\n",
    "        for instance in s_file:\n",
    "            instance = json.loads(instance) # loading a sample\n",
    "            urls = instance['urls'] # extracting list of links\n",
    "            website = []\n",
    "            for url in urls:\n",
    "                net = urlparse(url)\n",
    "                neto=net.netloc\n",
    "                website.append(neto)\n",
    "            instance['website'] = website # updating the sample with domain name\n",
    "            d_file.write((json.dumps(instance)+'\\n').encode('utf-8')) # writing in the new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print de cette colonne\n",
    "path_to_file = '2020a.json.bz2'\n",
    "\n",
    "with bz2.open(path_to_file, 'rb') as s_file:\n",
    "        for instance in s_file:\n",
    "            instance = json.loads(instance) # loading a sample\n",
    "            print(instance['website']) # extracting list of links   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df3=pd.DataFrame\n",
    "#columns='quoteID', 'quotation', 'speaker', 'qids', 'date', 'numOccurrences','probas', 'urls', 'phase', 'domains', 'website'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 11)\n",
      "(164, 11)\n",
      "(164, 11)\n",
      "Processing chunk with 250000 rows\n",
      "Index(['quoteID', 'quotation', 'speaker', 'qids', 'date', 'numOccurrences',\n",
      "       'probas', 'urls', 'phase', 'domains', 'website'],\n",
      "      dtype='object')\n",
      "(250000, 11)\n",
      "(163, 11)\n",
      "(327, 11)\n",
      "Processing chunk with 250000 rows\n",
      "Index(['quoteID', 'quotation', 'speaker', 'qids', 'date', 'numOccurrences',\n",
      "       'probas', 'urls', 'phase', 'domains', 'website'],\n",
      "      dtype='object')\n",
      "(250000, 11)\n",
      "(166, 11)\n",
      "(493, 11)\n",
      "Processing chunk with 250000 rows\n",
      "Index(['quoteID', 'quotation', 'speaker', 'qids', 'date', 'numOccurrences',\n",
      "       'probas', 'urls', 'phase', 'domains', 'website'],\n",
      "      dtype='object')\n",
      "(250000, 11)\n",
      "(151, 11)\n",
      "(644, 11)\n",
      "Processing chunk with 250000 rows\n",
      "Index(['quoteID', 'quotation', 'speaker', 'qids', 'date', 'numOccurrences',\n",
      "       'probas', 'urls', 'phase', 'domains', 'website'],\n",
      "      dtype='object')\n",
      "(250000, 11)\n",
      "(162, 11)\n",
      "(806, 11)\n",
      "Processing chunk with 250000 rows\n",
      "Index(['quoteID', 'quotation', 'speaker', 'qids', 'date', 'numOccurrences',\n",
      "       'probas', 'urls', 'phase', 'domains', 'website'],\n",
      "      dtype='object')\n",
      "(250000, 11)\n",
      "(189, 11)\n",
      "(995, 11)\n",
      "Processing chunk with 250000 rows\n",
      "Index(['quoteID', 'quotation', 'speaker', 'qids', 'date', 'numOccurrences',\n",
      "       'probas', 'urls', 'phase', 'domains', 'website'],\n",
      "      dtype='object')\n",
      "(250000, 11)\n",
      "(160, 11)\n",
      "(1155, 11)\n",
      "Processing chunk with 250000 rows\n",
      "Index(['quoteID', 'quotation', 'speaker', 'qids', 'date', 'numOccurrences',\n",
      "       'probas', 'urls', 'phase', 'domains', 'website'],\n",
      "      dtype='object')\n",
      "(250000, 11)\n",
      "(183, 11)\n",
      "(1338, 11)\n",
      "Processing chunk with 250000 rows\n",
      "Index(['quoteID', 'quotation', 'speaker', 'qids', 'date', 'numOccurrences',\n",
      "       'probas', 'urls', 'phase', 'domains', 'website'],\n",
      "      dtype='object')\n",
      "(250000, 11)\n",
      "(165, 11)\n",
      "(1503, 11)\n",
      "Processing chunk with 250000 rows\n",
      "Index(['quoteID', 'quotation', 'speaker', 'qids', 'date', 'numOccurrences',\n",
      "       'probas', 'urls', 'phase', 'domains', 'website'],\n",
      "      dtype='object')\n",
      "(250000, 11)\n",
      "(170, 11)\n",
      "(1673, 11)\n",
      "Processing chunk with 250000 rows\n",
      "Index(['quoteID', 'quotation', 'speaker', 'qids', 'date', 'numOccurrences',\n",
      "       'probas', 'urls', 'phase', 'domains', 'website'],\n",
      "      dtype='object')\n",
      "(250000, 11)\n",
      "(158, 11)\n",
      "(1831, 11)\n",
      "Processing chunk with 250000 rows\n",
      "Index(['quoteID', 'quotation', 'speaker', 'qids', 'date', 'numOccurrences',\n",
      "       'probas', 'urls', 'phase', 'domains', 'website'],\n",
      "      dtype='object')\n",
      "(250000, 11)\n",
      "(185, 11)\n",
      "(2016, 11)\n",
      "Processing chunk with 250000 rows\n",
      "Index(['quoteID', 'quotation', 'speaker', 'qids', 'date', 'numOccurrences',\n",
      "       'probas', 'urls', 'phase', 'domains', 'website'],\n",
      "      dtype='object')\n",
      "(250000, 11)\n",
      "(172, 11)\n",
      "(2188, 11)\n",
      "Processing chunk with 250000 rows\n",
      "Index(['quoteID', 'quotation', 'speaker', 'qids', 'date', 'numOccurrences',\n",
      "       'probas', 'urls', 'phase', 'domains', 'website'],\n",
      "      dtype='object')\n",
      "(250000, 11)\n",
      "(162, 11)\n",
      "(2350, 11)\n",
      "Processing chunk with 250000 rows\n",
      "Index(['quoteID', 'quotation', 'speaker', 'qids', 'date', 'numOccurrences',\n",
      "       'probas', 'urls', 'phase', 'domains', 'website'],\n",
      "      dtype='object')\n",
      "(250000, 11)\n",
      "(166, 11)\n",
      "(2516, 11)\n",
      "Processing chunk with 250000 rows\n",
      "Index(['quoteID', 'quotation', 'speaker', 'qids', 'date', 'numOccurrences',\n",
      "       'probas', 'urls', 'phase', 'domains', 'website'],\n",
      "      dtype='object')\n",
      "(250000, 11)\n",
      "(151, 11)\n",
      "(2667, 11)\n",
      "Processing chunk with 250000 rows\n",
      "Index(['quoteID', 'quotation', 'speaker', 'qids', 'date', 'numOccurrences',\n",
      "       'probas', 'urls', 'phase', 'domains', 'website'],\n",
      "      dtype='object')\n",
      "(250000, 11)\n",
      "(157, 11)\n",
      "(2824, 11)\n",
      "Processing chunk with 250000 rows\n",
      "Index(['quoteID', 'quotation', 'speaker', 'qids', 'date', 'numOccurrences',\n",
      "       'probas', 'urls', 'phase', 'domains', 'website'],\n",
      "      dtype='object')\n",
      "(250000, 11)\n",
      "(161, 11)\n",
      "(2985, 11)\n",
      "Processing chunk with 250000 rows\n",
      "Index(['quoteID', 'quotation', 'speaker', 'qids', 'date', 'numOccurrences',\n",
      "       'probas', 'urls', 'phase', 'domains', 'website'],\n",
      "      dtype='object')\n",
      "(250000, 11)\n",
      "(134, 11)\n",
      "(3119, 11)\n",
      "Processing chunk with 250000 rows\n",
      "Index(['quoteID', 'quotation', 'speaker', 'qids', 'date', 'numOccurrences',\n",
      "       'probas', 'urls', 'phase', 'domains', 'website'],\n",
      "      dtype='object')\n",
      "(250000, 11)\n",
      "(178, 11)\n",
      "(3297, 11)\n",
      "Processing chunk with 250000 rows\n",
      "Index(['quoteID', 'quotation', 'speaker', 'qids', 'date', 'numOccurrences',\n",
      "       'probas', 'urls', 'phase', 'domains', 'website'],\n",
      "      dtype='object')\n",
      "(244449, 11)\n",
      "(159, 11)\n",
      "(3456, 11)\n",
      "Processing chunk with 244449 rows\n",
      "Index(['quoteID', 'quotation', 'speaker', 'qids', 'date', 'numOccurrences',\n",
      "       'probas', 'urls', 'phase', 'domains', 'website'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "lista='quoteID', 'quotation', 'speaker', 'qids', 'date', 'numOccurrences','probas', 'urls', 'phase', 'domains', 'website'\n",
    "df2=pd.DataFrame(columns=lista)\n",
    "#creation du dataframe avec les citations avec le mot immigration \n",
    "def process_chunk(chunk,df2):\n",
    "        immi=pd.DataFrame()\n",
    "        immi=chunk[chunk['quotation'].str.contains(\"immigrat\")]\n",
    "        df2 = df2.append(immi)\n",
    "        print(df2.shape)\n",
    "        print(f'Processing chunk with {len(chunk)} rows')\n",
    "        print(chunk.columns)\n",
    "        return df2\n",
    "        \n",
    "for chunk in pd.read_json('2020a.json.bz2', lines=True, compression='bz2', chunksize=250000, encoding='utf-8'):\n",
    "    df2=process_chunk(chunk,df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quoteID</th>\n",
       "      <th>quotation</th>\n",
       "      <th>speaker</th>\n",
       "      <th>qids</th>\n",
       "      <th>date</th>\n",
       "      <th>numOccurrences</th>\n",
       "      <th>probas</th>\n",
       "      <th>urls</th>\n",
       "      <th>phase</th>\n",
       "      <th>domains</th>\n",
       "      <th>website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>2020-03-19-002801</td>\n",
       "      <td>All immigration to the US should be halted due...</td>\n",
       "      <td>Laura Ingraham</td>\n",
       "      <td>[Q266863]</td>\n",
       "      <td>2020-03-19 19:42:07</td>\n",
       "      <td>2</td>\n",
       "      <td>[[Laura Ingraham, 0.7681], [None, 0.2254], [Me...</td>\n",
       "      <td>[https://www.lifezette.com/2020/03/laura-ingra...</td>\n",
       "      <td>E</td>\n",
       "      <td>[com, com]</td>\n",
       "      <td>['www.lifezette.com', 'www.washingtonexaminer....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1970</td>\n",
       "      <td>2020-02-26-075062</td>\n",
       "      <td>This Government will get on and deliver a work...</td>\n",
       "      <td>Boris Johnson</td>\n",
       "      <td>[Q180589]</td>\n",
       "      <td>2020-02-26 13:49:26</td>\n",
       "      <td>55</td>\n",
       "      <td>[[Boris Johnson, 0.8695], [None, 0.1305]]</td>\n",
       "      <td>[http://www.expressandstar.com/news/uk-news/20...</td>\n",
       "      <td>E</td>\n",
       "      <td>[com, co.uk, co.uk, co.uk, co.uk, co.uk, co.uk...</td>\n",
       "      <td>['www.expressandstar.com', 'andoveradvertiser....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>2020-01-29-101344</td>\n",
       "      <td>This is among the more progressive attempts by...</td>\n",
       "      <td>García Hernández</td>\n",
       "      <td>[Q21844800]</td>\n",
       "      <td>2020-01-29 11:46:01</td>\n",
       "      <td>4</td>\n",
       "      <td>[[García Hernández, 0.5993], [None, 0.4007]]</td>\n",
       "      <td>[http://durangoherald.com/articles/312407-effo...</td>\n",
       "      <td>E</td>\n",
       "      <td>[com, com, com, com]</td>\n",
       "      <td>['durangoherald.com', 'www.vaildaily.com', 'ww...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3113</td>\n",
       "      <td>2020-01-23-027413</td>\n",
       "      <td>How come there is widespread breakdown of law ...</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>2020-01-23 17:37:00</td>\n",
       "      <td>1</td>\n",
       "      <td>[[None, 0.7086], [Abubakar Malami, 0.2914]]</td>\n",
       "      <td>[https://www.thenigerianvoice.com/news/284600/...</td>\n",
       "      <td>E</td>\n",
       "      <td>[com]</td>\n",
       "      <td>['www.thenigerianvoice.com']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4469</td>\n",
       "      <td>2020-03-19-071953</td>\n",
       "      <td>They had every right to be here and should nev...</td>\n",
       "      <td>Wendy Williams</td>\n",
       "      <td>[Q24004546, Q29643798, Q3559238, Q44627147, Q6...</td>\n",
       "      <td>2020-03-19 08:45:30</td>\n",
       "      <td>15</td>\n",
       "      <td>[[Wendy Williams, 0.9439], [None, 0.0524], [Pr...</td>\n",
       "      <td>[http://www.durangoherald.com/articles/318748-...</td>\n",
       "      <td>E</td>\n",
       "      <td>[com, com, com, com, com, com, com, com, com, ...</td>\n",
       "      <td>['www.durangoherald.com', 'wsls.com', 'www.loc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4831</td>\n",
       "      <td>2020-01-07-086951</td>\n",
       "      <td>We want to cover their lives, not just the imm...</td>\n",
       "      <td>Cristina Silva</td>\n",
       "      <td>[Q57161472, Q57811040]</td>\n",
       "      <td>2020-01-07 05:00:50</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Cristina Silva, 0.6561], [None, 0.3439]]</td>\n",
       "      <td>[https://digiday.com/media/usa-today-tests-bil...</td>\n",
       "      <td>E</td>\n",
       "      <td>[com]</td>\n",
       "      <td>['digiday.com']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6371</td>\n",
       "      <td>2020-02-23-024439</td>\n",
       "      <td>Officers will also look out for such traveller...</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>2020-02-23 17:27:16</td>\n",
       "      <td>1</td>\n",
       "      <td>[[None, 0.6227], [President Moon, 0.3773]]</td>\n",
       "      <td>[https://www.channelnewsasia.com/news/singapor...</td>\n",
       "      <td>E</td>\n",
       "      <td>[com]</td>\n",
       "      <td>['www.channelnewsasia.com']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6993</td>\n",
       "      <td>2020-02-17-069548</td>\n",
       "      <td>they wanted a fair system on immigration</td>\n",
       "      <td>Angela Rayner</td>\n",
       "      <td>[Q18164278]</td>\n",
       "      <td>2020-02-17 11:47:04</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Angela Rayner, 0.9138], [None, 0.0829], [Ros...</td>\n",
       "      <td>[http://www.theweek.co.uk/105727/angela-rayner...</td>\n",
       "      <td>E</td>\n",
       "      <td>[co.uk]</td>\n",
       "      <td>['www.theweek.co.uk']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9413</td>\n",
       "      <td>2020-04-03-059967</td>\n",
       "      <td>There are so many challenges: healthcare, immi...</td>\n",
       "      <td>Gina Ortiz Jones</td>\n",
       "      <td>[Q51754461]</td>\n",
       "      <td>2020-04-03 19:00:18</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Gina Ortiz Jones, 0.8175], [None, 0.1825]]</td>\n",
       "      <td>[https://www.lgbtqnation.com/2020/04/gina-orti...</td>\n",
       "      <td>E</td>\n",
       "      <td>[com]</td>\n",
       "      <td>['www.lgbtqnation.com']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9628</td>\n",
       "      <td>2020-04-16-056321</td>\n",
       "      <td>Under my plan, we will put Americans back to w...</td>\n",
       "      <td>Jeff Sessions</td>\n",
       "      <td>[Q358443]</td>\n",
       "      <td>2020-04-16 16:04:20</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Jeff Sessions, 0.8938], [None, 0.0776], [Tom...</td>\n",
       "      <td>[https://vdare.com/posts/jeff-sessions-calls-f...</td>\n",
       "      <td>E</td>\n",
       "      <td>[com]</td>\n",
       "      <td>['vdare.com']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                quoteID                                          quotation  \\\n",
       "74    2020-03-19-002801  All immigration to the US should be halted due...   \n",
       "1970  2020-02-26-075062  This Government will get on and deliver a work...   \n",
       "1980  2020-01-29-101344  This is among the more progressive attempts by...   \n",
       "3113  2020-01-23-027413  How come there is widespread breakdown of law ...   \n",
       "4469  2020-03-19-071953  They had every right to be here and should nev...   \n",
       "4831  2020-01-07-086951  We want to cover their lives, not just the imm...   \n",
       "6371  2020-02-23-024439  Officers will also look out for such traveller...   \n",
       "6993  2020-02-17-069548           they wanted a fair system on immigration   \n",
       "9413  2020-04-03-059967  There are so many challenges: healthcare, immi...   \n",
       "9628  2020-04-16-056321  Under my plan, we will put Americans back to w...   \n",
       "\n",
       "               speaker                                               qids  \\\n",
       "74      Laura Ingraham                                          [Q266863]   \n",
       "1970     Boris Johnson                                          [Q180589]   \n",
       "1980  García Hernández                                        [Q21844800]   \n",
       "3113              None                                                 []   \n",
       "4469    Wendy Williams  [Q24004546, Q29643798, Q3559238, Q44627147, Q6...   \n",
       "4831    Cristina Silva                             [Q57161472, Q57811040]   \n",
       "6371              None                                                 []   \n",
       "6993     Angela Rayner                                        [Q18164278]   \n",
       "9413  Gina Ortiz Jones                                        [Q51754461]   \n",
       "9628     Jeff Sessions                                          [Q358443]   \n",
       "\n",
       "                    date numOccurrences  \\\n",
       "74   2020-03-19 19:42:07              2   \n",
       "1970 2020-02-26 13:49:26             55   \n",
       "1980 2020-01-29 11:46:01              4   \n",
       "3113 2020-01-23 17:37:00              1   \n",
       "4469 2020-03-19 08:45:30             15   \n",
       "4831 2020-01-07 05:00:50              1   \n",
       "6371 2020-02-23 17:27:16              1   \n",
       "6993 2020-02-17 11:47:04              1   \n",
       "9413 2020-04-03 19:00:18              1   \n",
       "9628 2020-04-16 16:04:20              1   \n",
       "\n",
       "                                                 probas  \\\n",
       "74    [[Laura Ingraham, 0.7681], [None, 0.2254], [Me...   \n",
       "1970          [[Boris Johnson, 0.8695], [None, 0.1305]]   \n",
       "1980       [[García Hernández, 0.5993], [None, 0.4007]]   \n",
       "3113        [[None, 0.7086], [Abubakar Malami, 0.2914]]   \n",
       "4469  [[Wendy Williams, 0.9439], [None, 0.0524], [Pr...   \n",
       "4831         [[Cristina Silva, 0.6561], [None, 0.3439]]   \n",
       "6371         [[None, 0.6227], [President Moon, 0.3773]]   \n",
       "6993  [[Angela Rayner, 0.9138], [None, 0.0829], [Ros...   \n",
       "9413       [[Gina Ortiz Jones, 0.8175], [None, 0.1825]]   \n",
       "9628  [[Jeff Sessions, 0.8938], [None, 0.0776], [Tom...   \n",
       "\n",
       "                                                   urls phase  \\\n",
       "74    [https://www.lifezette.com/2020/03/laura-ingra...     E   \n",
       "1970  [http://www.expressandstar.com/news/uk-news/20...     E   \n",
       "1980  [http://durangoherald.com/articles/312407-effo...     E   \n",
       "3113  [https://www.thenigerianvoice.com/news/284600/...     E   \n",
       "4469  [http://www.durangoherald.com/articles/318748-...     E   \n",
       "4831  [https://digiday.com/media/usa-today-tests-bil...     E   \n",
       "6371  [https://www.channelnewsasia.com/news/singapor...     E   \n",
       "6993  [http://www.theweek.co.uk/105727/angela-rayner...     E   \n",
       "9413  [https://www.lgbtqnation.com/2020/04/gina-orti...     E   \n",
       "9628  [https://vdare.com/posts/jeff-sessions-calls-f...     E   \n",
       "\n",
       "                                                domains  \\\n",
       "74                                           [com, com]   \n",
       "1970  [com, co.uk, co.uk, co.uk, co.uk, co.uk, co.uk...   \n",
       "1980                               [com, com, com, com]   \n",
       "3113                                              [com]   \n",
       "4469  [com, com, com, com, com, com, com, com, com, ...   \n",
       "4831                                              [com]   \n",
       "6371                                              [com]   \n",
       "6993                                            [co.uk]   \n",
       "9413                                              [com]   \n",
       "9628                                              [com]   \n",
       "\n",
       "                                                website  \n",
       "74    ['www.lifezette.com', 'www.washingtonexaminer....  \n",
       "1970  ['www.expressandstar.com', 'andoveradvertiser....  \n",
       "1980  ['durangoherald.com', 'www.vaildaily.com', 'ww...  \n",
       "3113                       ['www.thenigerianvoice.com']  \n",
       "4469  ['www.durangoherald.com', 'wsls.com', 'www.loc...  \n",
       "4831                                    ['digiday.com']  \n",
       "6371                        ['www.channelnewsasia.com']  \n",
       "6993                              ['www.theweek.co.uk']  \n",
       "9413                            ['www.lgbtqnation.com']  \n",
       "9628                                      ['vdare.com']  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3456, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['www.msn.com']</td>\n",
       "      <td>1202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['express.co.uk']</td>\n",
       "      <td>1184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['www.cheatsheet.com']</td>\n",
       "      <td>925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['www.bostonglobe.com']</td>\n",
       "      <td>769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['www.foxnews.com']</td>\n",
       "      <td>763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['timesofindia.indiatimes.com']</td>\n",
       "      <td>745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['www.dailystar.co.uk']</td>\n",
       "      <td>742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['www.telegraph.co.uk']</td>\n",
       "      <td>741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['indianexpress.com']</td>\n",
       "      <td>741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['www.thesun.co.uk']</td>\n",
       "      <td>730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['www.thehindu.com']</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['www.breitbart.com']</td>\n",
       "      <td>717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['www.forbes.com']</td>\n",
       "      <td>703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['www.mirror.co.uk']</td>\n",
       "      <td>642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['www.bbc.co.uk']</td>\n",
       "      <td>631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['www.washingtonexaminer.com']</td>\n",
       "      <td>596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['www.hindustantimes.com']</td>\n",
       "      <td>581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['www.theguardian.com']</td>\n",
       "      <td>544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['msn.com']</td>\n",
       "      <td>539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['www.latimes.com']</td>\n",
       "      <td>523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 website\n",
       "['www.msn.com']                     1202\n",
       "['express.co.uk']                   1184\n",
       "['www.cheatsheet.com']               925\n",
       "['www.bostonglobe.com']              769\n",
       "['www.foxnews.com']                  763\n",
       "['timesofindia.indiatimes.com']      745\n",
       "['www.dailystar.co.uk']              742\n",
       "['www.telegraph.co.uk']              741\n",
       "['indianexpress.com']                741\n",
       "['www.thesun.co.uk']                 730\n",
       "['www.thehindu.com']                 722\n",
       "['www.breitbart.com']                717\n",
       "['www.forbes.com']                   703\n",
       "['www.mirror.co.uk']                 642\n",
       "['www.bbc.co.uk']                    631\n",
       "['www.washingtonexaminer.com']       596\n",
       "['www.hindustantimes.com']           581\n",
       "['www.theguardian.com']              544\n",
       "['msn.com']                          539\n",
       "['www.latimes.com']                  523"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lis=chunk['website'].value_counts().to_frame()\n",
    "lis.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>None</td>\n",
       "      <td>84128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>President Donald Trump</td>\n",
       "      <td>1258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Bernie Sanders</td>\n",
       "      <td>595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Joe Biden</td>\n",
       "      <td>581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>President Trump</td>\n",
       "      <td>546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kirstjen Nielsen</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Jennifer Anderson</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>alan tongue</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Wes Welker</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Blake Hardwick</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62330 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        speaker\n",
       "None                      84128\n",
       "President Donald Trump     1258\n",
       "Bernie Sanders              595\n",
       "Joe Biden                   581\n",
       "President Trump             546\n",
       "...                         ...\n",
       "Kirstjen Nielsen              1\n",
       "Jennifer Anderson             1\n",
       "alan tongue                   1\n",
       "Wes Welker                    1\n",
       "Blake Hardwick                1\n",
       "\n",
       "[62330 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk['speaker'].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk['website']=chunk['website'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation d'un dataframe pour quelques journaux\n",
    "fox=chunk[chunk['website'].str.contains(\"www.foxnews.com\")]\n",
    "ny=chunk[chunk['website'].str.contains(\"www.nytimes.com\")]\n",
    "brei=chunk[chunk['website'].str.contains(\"www.breitbart.com\")]\n",
    "cnn=chunk[chunk['website'].str.contains(\"cnn.com\")]\n",
    "guard=chunk[chunk['website'].str.contains(\"www.theguardian.com\")]\n",
    "slate=chunk[chunk['website'].str.contains(\"slate.com\")]\n",
    "buzz=chunk[chunk['website'].str.contains(\"buzzfeed.com\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "fox_quotes=fox['quotation']\n",
    "ny_quotes=ny['quotation']\n",
    "brei_quotes=brei['quotation']\n",
    "cnn_quotes=cnn['quotation']\n",
    "guard_quotes=guard['quotation']\n",
    "slate_quotes=slate['quotation']\n",
    "buzz_quotes=buzz['quotation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1787, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fox.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1284, 11)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ny.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3708, 11)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brei.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1446, 11)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(687, 11)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guard.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123, 11)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(279, 11)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buzz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11182372691661988 0.07998601007274761\n"
     ]
    }
   ],
   "source": [
    "#analyse de sentiments positif et negatif pour les journaux précédemment choisis\n",
    "pos=0\n",
    "neg=0\n",
    "average_pos=0\n",
    "average_neg=0\n",
    "for quotation in fox_quotes:\n",
    "    result=sia.polarity_scores(quotation)\n",
    "    pos=pos+result[\"pos\"]\n",
    "    neg=neg+result[\"neg\"]\n",
    "average_pos=pos/1787\n",
    "average_neg=neg/1787\n",
    "print(average_pos,average_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10962928348909654 0.07516510903426793\n"
     ]
    }
   ],
   "source": [
    "pos=0\n",
    "neg=0\n",
    "average_pos=0\n",
    "average_neg=0\n",
    "for quotation in ny_quotes:\n",
    "    result=sia.polarity_scores(quotation)\n",
    "    pos=pos+result[\"pos\"]\n",
    "    neg=neg+result[\"neg\"]\n",
    "average_pos=pos/1284\n",
    "average_neg=neg/1284\n",
    "print(average_pos,average_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12019363538295594 0.0813460086299893\n"
     ]
    }
   ],
   "source": [
    "pos=0\n",
    "neg=0\n",
    "average_pos=0\n",
    "average_neg=0\n",
    "for quotation in brei_quotes:\n",
    "    result=sia.polarity_scores(quotation)\n",
    "    pos=pos+result[\"pos\"]\n",
    "    neg=neg+result[\"neg\"]\n",
    "average_pos=pos/3708\n",
    "average_neg=neg/3708\n",
    "print(average_pos,average_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.113540110650069 0.06954356846473027\n"
     ]
    }
   ],
   "source": [
    "pos=0\n",
    "neg=0\n",
    "average_pos=0\n",
    "average_neg=0\n",
    "for quotation in cnn_quotes:\n",
    "    result=sia.polarity_scores(quotation)\n",
    "    pos=pos+result[\"pos\"]\n",
    "    neg=neg+result[\"neg\"]\n",
    "average_pos=pos/1446\n",
    "average_neg=neg/1446\n",
    "print(average_pos,average_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11037845705967979 0.07798107714701595\n"
     ]
    }
   ],
   "source": [
    "pos=0\n",
    "neg=0\n",
    "average_pos=0\n",
    "average_neg=0\n",
    "for quotation in guard_quotes:\n",
    "    result=sia.polarity_scores(quotation)\n",
    "    pos=pos+result[\"pos\"]\n",
    "    neg=neg+result[\"neg\"]\n",
    "average_pos=pos/687\n",
    "average_neg=neg/687\n",
    "print(average_pos,average_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09873170731707316 0.07367479674796752\n"
     ]
    }
   ],
   "source": [
    "pos=0\n",
    "neg=0\n",
    "average_pos=0\n",
    "average_neg=0\n",
    "for quotation in slate_quotes:\n",
    "    result=sia.polarity_scores(quotation)\n",
    "    pos=pos+result[\"pos\"]\n",
    "    neg=neg+result[\"neg\"]\n",
    "average_pos=pos/123\n",
    "average_neg=neg/123\n",
    "print(average_pos,average_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1609749103942653 0.06458064516129029\n"
     ]
    }
   ],
   "source": [
    "pos=0\n",
    "neg=0\n",
    "average_pos=0\n",
    "average_neg=0\n",
    "for quotation in buzz_quotes:\n",
    "    result=sia.polarity_scores(quotation)\n",
    "    pos=pos+result[\"pos\"]\n",
    "    neg=neg+result[\"neg\"]\n",
    "average_pos=pos/279\n",
    "average_neg=neg/279\n",
    "print(average_pos,average_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 11)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immi=chunk[chunk['quotation'].str.contains(\"\")]\n",
    "immi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_quotes=df2['quotation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09833275462962988 0.08480266203703696\n"
     ]
    }
   ],
   "source": [
    "pos=0\n",
    "neg=0\n",
    "average_pos=0\n",
    "average_neg=0\n",
    "for quotation in df2_quotes:\n",
    "    result=sia.polarity_scores(quotation)\n",
    "    pos=pos+result[\"pos\"]\n",
    "    neg=neg+result[\"neg\"]\n",
    "average_pos=pos/3456\n",
    "average_neg=neg/3456\n",
    "print(average_pos,average_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['website']=df2['website'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fox_immi=df2[df2['website'].str.contains(\"foxnews.com\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, 11)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fox_immi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12042045454545452 0.10822727272727271\n"
     ]
    }
   ],
   "source": [
    "pos=0\n",
    "neg=0\n",
    "average_pos=0\n",
    "average_neg=0\n",
    "for quotation in fox_immi['quotation']:\n",
    "    result=sia.polarity_scores(quotation)\n",
    "    pos=pos+result[\"pos\"]\n",
    "    neg=neg+result[\"neg\"]\n",
    "average_pos=pos/88\n",
    "average_neg=neg/88\n",
    "print(average_pos,average_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
