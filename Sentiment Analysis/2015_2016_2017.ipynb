{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Year by year, 2015, 2016 and 2017 sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook compare the sentiments of all the quotes from Foxnews and the Ny times for the year 2015, 2016 and 2017. Some of the notable discorevies on this notebook are:\n",
    "    - There is a big difference for negative sentiments for the years 2016 and 2017 between the two journals in NLTK          analysis\n",
    "    - There is a big difference for negative sentiments for the dataset with all the years between the two journals in NLTK analysis\n",
    "    - The 2015 year does not appear to be the best to differenciate the two journals with the nltk analysis\n",
    "    - The 2015 year has great differences in the text2emotion analysis\n",
    "    - There is a big difference for surprise and sadness between the two journals in the text2emotion analysis for all years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "- [NLTK for ALL YEARS](#n)\n",
    "- [2015](#15)\n",
    "- [2015 NLTK](#15n)\n",
    "- [2015 Text2emotion](#15t)\n",
    "- [2016](#16)\n",
    "- [2016 NLTK](#16n)\n",
    "- [2016 Text2emotion](#16t)\n",
    "- [2017](#17)\n",
    "- [2017 NLTK](#17n)\n",
    "- [2017 Text2emotion](#17t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bz2\n",
    "import json\n",
    "from urllib.parse import urlparse\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import os\n",
    "import glob\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_yearly(y):\n",
    "    PATH = 'Fox_NY_' + str(y) + '/'\n",
    "    nb = 1\n",
    "    df2 = []\n",
    "    dirs = glob.glob(os.path.join(PATH, \"*.pkl\"))\n",
    "\n",
    "    for files in dirs:\n",
    "        df1 = pd.read_pickle(PATH + str(nb)+ '_' + str(y) + '_' + 'FoxNYtimes.pkl')\n",
    "        df2.append(df1)\n",
    "        nb += 1\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2015, 2016, 2017, 2018, 2019, 2020]\n",
    "df_foxNy = pd.DataFrame()\n",
    "\n",
    "for y in years:\n",
    "    df_foxNy = df_foxNy.append(pd.concat(read_yearly(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The chosen key words are selected here\n",
    "words_immigration = 'immigration|mexic|migrant|border|refugees'\n",
    "words_terrorism = 'shoot|gun|kill|attack|massacre|victim|terroris|arm|violen|death'\n",
    "words_ClimateChange = 'flood|greenhouse effect|CO2|global warming|pollution|glacier|ice pake melting|high temperatures|heat'\n",
    "words_abortion = 'abort|fetus'\n",
    "words_religion = 'God|Christian|Christianism|Belief|faith|prayer|commitment|islam|buddhism|hinduism|baptism|church|vatican|reincarnation|jesus'\n",
    "words_racism = 'White|Black|Black lives matter|All lives matter|discrimination|Segregation|George Floyd|Slaver|White supremacy|Klu Klux Klan|KKK|Gunshot|Trials|Police|Death sentence'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK for ALL YEARS<a name=\"n\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "from collections import namedtuple\n",
    "import text2emotion as te\n",
    "df_fox = df_foxNy[df_foxNy['urls'].str.contains('foxnews')]\n",
    "df_ny = df_foxNy[df_foxNy['urls'].str.contains('nytimes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of positif and negatif feelings found respectively are: 0.11145302076188893 0.07574319832250949\n",
      "101892.91499999638 69246.17399999959 914223\n"
     ]
    }
   ],
   "source": [
    "pos = 0\n",
    "neg = 0\n",
    "length = 0\n",
    "pos,neg,length = fon_nltk(df_ny)\n",
    "print(pos,neg,length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of positif and negatif feelings found respectively are: 0.11496761055720493 0.0868546198788612\n",
      "83669.74799999592 63210.01299999906 727768\n"
     ]
    }
   ],
   "source": [
    "pos = 0\n",
    "neg = 0\n",
    "length = 0\n",
    "pos,neg,length = fon_nltk(df_fox)\n",
    "print(pos,neg,length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fon_text2 (df):\n",
    "    Desc = namedtuple(\"Desc\", [\"fear\", \"happy\", \"angry\",\"surprise\",\"sad\",\"length\"])\n",
    "    df_quotes = df['quotation']\n",
    "    dfsize = len(df_quotes)\n",
    "    fear = 0\n",
    "    happy = 0\n",
    "    angry = 0\n",
    "    surprise = 0\n",
    "    sad = 0\n",
    "    average_fear = 0\n",
    "    average_happy = 0\n",
    "    average_angry = 0\n",
    "    average_surprise = 0\n",
    "    average_sad = 0\n",
    "\n",
    "    for quotation in df_quotes:\n",
    "        di = te.get_emotion(quotation)\n",
    "        fear += di.get('Fear')\n",
    "        happy += di.get('Happy')\n",
    "        angry += di.get('Angry')\n",
    "        surprise += di.get('Surprise')\n",
    "        sad += di.get('Sad')\n",
    "    average_fear = fear/dfsize\n",
    "    average_happy = happy/dfsize\n",
    "    average_angry = angry/dfsize\n",
    "    average_surprise = surprise/dfsize\n",
    "    average_sad = sad/dfsize\n",
    "\n",
    "    print(\"fear{}, happy{}, angry{}, surprise{}, sad{}\".format(average_fear,average_happy,\n",
    "                                                               average_angry,average_surprise,average_sad))\n",
    "    return (Desc(fear,happy,angry,surprise,sad,dfsize,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fon_nltk (df):\n",
    "    Desc = namedtuple(\"Desc\", [\"pos\", \"neg\", \"tot\"])\n",
    "    quotes = df['quotation']\n",
    "    length = len(df)\n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    average_pos = 0\n",
    "    average_neg = 0\n",
    "    for quotation in quotes:\n",
    "        result = sia.polarity_scores(quotation)\n",
    "        pos += result[\"pos\"]\n",
    "        neg += result[\"neg\"]\n",
    "    average_pos = pos/length\n",
    "    average_neg = neg/length\n",
    "    print('Mean of positif and negatif feelings found respectively are:', average_pos,average_neg)\n",
    "    return (Desc(pos, neg, length,))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2015<a name=\"15\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2015]\n",
    "df_foxNy1 = pd.DataFrame()\n",
    "\n",
    "for y in years:\n",
    "    df_foxNy1 = df_foxNy1.append(pd.concat(read_yearly(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "from collections import namedtuple\n",
    "import text2emotion as te\n",
    "df_fox1 = df_foxNy1[df_foxNy1['urls'].str.contains('foxnews')]\n",
    "df_ny1 = df_foxNy1[df_foxNy1['urls'].str.contains('nytimes')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2015 NLTK<a name=\"15n\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of positif and negatif feelings found respectively are: 0.11111932454553282 0.08762264150943382\n",
      "1289.7619999999995 1017.0359999999984 11607\n"
     ]
    }
   ],
   "source": [
    "pos = 0\n",
    "neg = 0\n",
    "length = 0\n",
    "pos, neg, length = fon_nltk(df_ny1)\n",
    "print(pos, neg, length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of positif and negatif feelings found respectively are: 0.1170303760807516 0.08460186549682747\n",
      "13738.780999999835 9931.836000000061 117395\n"
     ]
    }
   ],
   "source": [
    "pos = 0\n",
    "neg = 0\n",
    "length = 0\n",
    "pos, neg, length = fon_nltk(df_fox1)\n",
    "print(pos, neg, length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2015 Text2emotion<a name=\"15t\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fear0.28850952011716924, happy0.09200137847850502, angry0.04556991470664246, surprise0.1587412768157147, sad0.17536831222538113\n",
      "3348.7299999999836 1067.8600000000079 528.929999999999 1842.5100000000007 2035.4999999999986 11607\n"
     ]
    }
   ],
   "source": [
    "fear = 0\n",
    "happy = 0\n",
    "angry = 0\n",
    "surprise = 0\n",
    "sad = 0\n",
    "tot = 0\n",
    "\n",
    "fear, happy, angry, surprise, sad, tot = fon_text2(df_ny1)\n",
    "print(fear, happy, angry, surprise, sad, tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fear0.3453386430427476, happy0.10540082627028634, angry0.04623876655734708, surprise0.18508028450959127, sad0.19682661101413393\n",
      "40541.03000000335 12373.530000000264 5428.199999999761 21727.500000003467 23106.460000004252 117395\n"
     ]
    }
   ],
   "source": [
    "fear = 0\n",
    "happy = 0\n",
    "angry = 0\n",
    "surprise = 0\n",
    "sad = 0\n",
    "tot = 0\n",
    "\n",
    "fear, happy, angry, surprise, sad, tot = fon_text2(df_fox1)\n",
    "print(fear, happy, angry, surprise, sad, tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2016<a name=\"16\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2016]\n",
    "df_foxNy2 = pd.DataFrame()\n",
    "\n",
    "for y in years:\n",
    "    df_foxNy2 = df_foxNy2.append(pd.concat(read_yearly(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "from collections import namedtuple\n",
    "import text2emotion as te\n",
    "df_fox2 = df_foxNy2[df_foxNy2['urls'].str.contains('foxnews')]\n",
    "df_ny2 = df_foxNy2[df_foxNy2['urls'].str.contains('nytimes')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2016 NLTK<a name=\"16n\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of positif and negatif feelings found respectively are: 0.11859536287686784 0.07555322827908305\n",
      "19958.887999999595 12715.155000000002 168294\n"
     ]
    }
   ],
   "source": [
    "pos = 0\n",
    "neg = 0\n",
    "length = 0\n",
    "pos, neg, length = fon_nltk(df_ny2)\n",
    "print(pos, neg, length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of positif and negatif feelings found respectively are: 0.11577186587975913 0.08982915883001527\n",
      "8925.43200000003 6925.379000000027 77095\n"
     ]
    }
   ],
   "source": [
    "pos = 0\n",
    "neg = 0\n",
    "length = 0\n",
    "pos, neg, length = fon_nltk(df_fox2)\n",
    "print(pos, neg, length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2016 Text2emotion<a name=\"t\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fear0.3391442356828181, happy0.1048020131436742, angry0.047251060643870996, surprise0.18007510665863127, sad0.1919055343625344\n",
      "57075.94000000419 17637.550000001505 7952.069999999625 30305.560000007692 32296.550000008367 168294\n"
     ]
    }
   ],
   "source": [
    "fear = 0\n",
    "happy = 0\n",
    "angry = 0\n",
    "surprise = 0\n",
    "sad = 0\n",
    "tot = 0\n",
    "\n",
    "fear, happy, angry, surprise, sad, tot = fon_text2(df_ny2)\n",
    "print(fear, happy, angry, surprise, sad, tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fear0.3409877423957702, happy0.10286516635319636, angry0.04630053829690464, surprise0.18898839094623937, sad0.19974343342629722\n",
      "26288.450000001903 7930.389999999673 3569.5399999998635 14570.060000000323 15399.220000000383 77095\n"
     ]
    }
   ],
   "source": [
    "fear = 0\n",
    "happy = 0\n",
    "angry = 0\n",
    "surprise = 0\n",
    "sad = 0\n",
    "tot = 0\n",
    "\n",
    "fear, happy, angry, surprise, sad, tot = fon_text2(df_fox2)\n",
    "print(fear, happy, angry, surprise, sad, tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2017<a name=\"17\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2017]\n",
    "df_foxNy3 = pd.DataFrame()\n",
    "\n",
    "for y in years:\n",
    "    df_foxNy3 = df_foxNy3.append(pd.concat(read_yearly(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "from collections import namedtuple\n",
    "import text2emotion as te\n",
    "df_fox3 = df_foxNy3[df_foxNy3['urls'].str.contains('foxnews')]\n",
    "df_ny3 = df_foxNy3[df_foxNy3['urls'].str.contains('nytimes')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2017 NLTK<a name=\"17n\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of positif and negatif feelings found respectively are: 0.11057157774211553 0.07493777566340601\n",
      "27425.95299999885 18587.4159999999 248038\n"
     ]
    }
   ],
   "source": [
    "pos = 0\n",
    "neg = 0\n",
    "length = 0\n",
    "pos,neg,length = fon_nltk(df_ny3)\n",
    "print(pos, neg, length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of positif and negatif feelings found respectively are: 0.11459294820426734 0.09031551686457373\n",
      "15730.173999999777 12397.611000000035 137270\n"
     ]
    }
   ],
   "source": [
    "pos = 0\n",
    "neg = 0\n",
    "length = 0\n",
    "pos, neg, length = fon_nltk(df_fox3)\n",
    "print(pos, neg, length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2017 Text2emotion<a name=\"17t\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fear0.3396533595658813, happy0.09708322918264674, angry0.04657504092115008, surprise0.1790039832606699, sad0.1896396923052509\n",
      "84246.94000000205 24080.33000000533 11552.380000000223 44399.79000001004 47037.85000000982 248038\n"
     ]
    }
   ],
   "source": [
    "fear = 0\n",
    "happy = 0\n",
    "angry = 0\n",
    "surprise = 0\n",
    "sad = 0\n",
    "tot = 0\n",
    "\n",
    "fear, happy, angry, surprise, sad, tot = fon_text2(df_ny3)\n",
    "print(fear, happy, angry, surprise, sad, tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fear0.3400061193269057, happy0.10251577183653081, angry0.0471811757849472, surprise0.19248306257744463, sad0.2006994973410505\n",
      "46672.64000000435 14072.340000000584 6476.559999999703 26422.150000005826 27550.020000006003 137270\n"
     ]
    }
   ],
   "source": [
    "fear = 0\n",
    "happy = 0\n",
    "angry = 0\n",
    "surprise = 0\n",
    "sad = 0\n",
    "tot = 0\n",
    "\n",
    "fear, happy, angry, surprise, sad, tot = fon_text2(df_fox3)\n",
    "print(fear, happy, angry, surprise, sad, tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
