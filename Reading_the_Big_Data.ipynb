{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reading_the_Big_Data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjRefaJPk7d4"
      },
      "source": [
        "# Project ADA: Part 1 Read Data and Load DataFrame for all the Years"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cv19i44Wpf6k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d4c6134-ee56-4d32-aed0-12af82179952"
      },
      "source": [
        "from google.colab import drive\n",
        "drive._mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.activity.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fexperimentsandconfigs%20https%3a%2f%2fwww.googleapis.com%2fauth%2fphotos.native&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "4/1AX4XfWjrJp0JvSODfPWXHpRdP-0vgRMVQ8kNRYj4gPdisbKNKhvwwJ_ZmZE\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfnFsmbCpqrs"
      },
      "source": [
        "!pip install pandas==1.0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIAN3Z0Sk7d_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4e5dedd-5dcb-4b3b-a28c-661e3f3d02d7"
      },
      "source": [
        "import seaborn as sns\n",
        "from IPython.display import display, HTML\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import bz2\n",
        "import json\n",
        "from urllib.parse import urlparse\n",
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "import os\n",
        "import glob\n",
        "import pickle"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rh99Atrck7eK"
      },
      "source": [
        "## Create Dataframe for each journal \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHobZi1sG6j6"
      },
      "source": [
        "def process_chunk(chunk, year, nb):\n",
        "    df_chunk = pd.DataFrame()\n",
        "    df = pd.DataFrame()\n",
        "    \n",
        "    df_chunk = chunk.drop(['qids', 'phase'], axis=1) #axis=1 for columns\n",
        "    \n",
        "    df_chunk['urls'] = df_chunk['urls'].astype('str') #Converting to string to be able to use str.contains \n",
        "    df_1 = df_chunk[df_chunk['urls'].str.contains('foxnews')] #Creating a DataFrame containing only foxnews\n",
        "    df_2 = df_chunk[df_chunk['urls'].str.contains('nytimes')]\n",
        "    df = pd.concat([df_1, df_2])\n",
        "\n",
        "    df.to_pickle('/content/drive/MyDrive/ADA_2021/Fox_NY_' + str(year) + '/' + str(nb) + '_' +  str(year) + '_' + 'FoxNYtimes.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPkOHIT7G8gT"
      },
      "source": [
        "years = [2015, 2016, 2017, 2018, 2019, 2020]\n",
        "for y in years:\n",
        "    nb = 1\n",
        "    for chunk in pd.read_json('/content/drive/MyDrive/Quotebank/quotes-' + str(y) + '.json.bz2', \n",
        "                              lines=True, compression='bz2', chunksize=500000, encoding='utf-8'):\n",
        "      \n",
        "      process_chunk(chunk, y, nb)\n",
        "      nb += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXEmeZ4GHBJF"
      },
      "source": [
        "def read_yearly(y):\n",
        "    PATH = '/content/drive/MyDrive/ADA_2021/Fox_NY_' + str(y) + '/'\n",
        "    nb = 1\n",
        "    df1 = pd.DataFrame()\n",
        "    df2 = []\n",
        "    dirs = glob.glob(os.path.join(PATH, \"*.pkl\"))\n",
        "\n",
        "    for files in dirs:\n",
        "        df1 = pd.read_pickle(PATH + str(nb)+ '_' + str(y) + '_' + 'FoxNYtimes.pkl')\n",
        "        df2.append(df1)\n",
        "        nb += 1\n",
        "    return df2"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "years = [2015, 2016, 2017, 2018, 2019, 2020]\n",
        "df_foxNY = pd.DataFrame()\n",
        "\n",
        "for y in years:\n",
        "  df_foxNY = df_foxNY.append(read_yearly(y))"
      ],
      "metadata": {
        "id": "qCkWHT2FINLA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_foxNY.sample(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "f_KVPPs4MSk0",
        "outputId": "96f196d0-ef00-4ff5-8bee-bbeaab40be99"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>quoteID</th>\n",
              "      <th>quotation</th>\n",
              "      <th>speaker</th>\n",
              "      <th>date</th>\n",
              "      <th>numOccurrences</th>\n",
              "      <th>probas</th>\n",
              "      <th>urls</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9604225</th>\n",
              "      <td>2017-08-22-154821</td>\n",
              "      <td>who love our kids.</td>\n",
              "      <td>Peter Sellars</td>\n",
              "      <td>2017-08-22 14:43:19</td>\n",
              "      <td>3</td>\n",
              "      <td>[[Peter Sellars, 0.8143], [None, 0.1392], [Joh...</td>\n",
              "      <td>['https://www.nytimes.com/2017/08/22/arts/musi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7272252</th>\n",
              "      <td>2015-04-29-012495</td>\n",
              "      <td>Money (Burns A Hole In My Pocket),</td>\n",
              "      <td>Dean Martin</td>\n",
              "      <td>2015-04-29 11:18:01</td>\n",
              "      <td>5</td>\n",
              "      <td>[[Dean Martin, 0.6388], [None, 0.3241], [Jared...</td>\n",
              "      <td>['http://communityvoices.post-gazette.com/arts...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18635814</th>\n",
              "      <td>2017-05-12-029784</td>\n",
              "      <td>He likes to keep the brother role more than te...</td>\n",
              "      <td>Novak Djokovic</td>\n",
              "      <td>2017-05-12 00:45:55</td>\n",
              "      <td>1</td>\n",
              "      <td>[[Novak Djokovic, 0.7629], [None, 0.2298], [An...</td>\n",
              "      <td>['https://www.nytimes.com/2017/05/11/sports/te...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    quoteID  ...                                               urls\n",
              "9604225   2017-08-22-154821  ...  ['https://www.nytimes.com/2017/08/22/arts/musi...\n",
              "7272252   2015-04-29-012495  ...  ['http://communityvoices.post-gazette.com/arts...\n",
              "18635814  2017-05-12-029784  ...  ['https://www.nytimes.com/2017/05/11/sports/te...\n",
              "\n",
              "[3 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking if Filtering is Needed"
      ],
      "metadata": {
        "id": "cXZfOc6VpS9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculates duplicated rows in the DataFrame\n",
        "# There are duplicat rows in the DataFrame because sometimes both journal will provide the same quotation\n",
        "num_duplicates = len(df_foxNY[df_foxNY.duplicated(subset=['quoteID', 'quotation', 'date', 'urls'])])\n",
        "print(\"There are {} duplicated rows\".format(num_duplicates))\n",
        "\n",
        "#Removes duplicated rows\n",
        "df_foxNY = df_foxNY.drop_duplicates(subset=['quoteID', 'quotation', 'date', 'urls'], keep=\"first\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lpk-IkTbPUC",
        "outputId": "44810dbf-bb04-42c4-c324-db6660feccb7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 19385 duplicated rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Searching for Missing Values\n",
        "def MissingValuesFilter(chunk):\n",
        "        #Gives True as a result, if the lines where NaN are presents are empty \n",
        "        #(meaning there are no NaNs):\n",
        "        missing_nan = pd.DataFrame(np.where(chunk.isnull().any(axis=1))).empty\n",
        "        #Gives True as a result if the lignes and corresponding columns where \n",
        "        #zeros, '' and None are found are empty:\n",
        "        missing_zeros = pd.DataFrame(np.where(chunk==0)).empty \n",
        "        missing_space = pd.DataFrame(np.where(chunk=='')).empty\n",
        "        missing_none = pd.DataFrame(np.where(chunk==None)).empty\n",
        "        #missing_brackets = pd.DataFrame(np.where(chunk==[])).empty\n",
        "\n",
        "        print('This DataFrame does not contain missing values')\n",
        "        print(missing_nan, missing_zeros, missing_space, missing_none) \n",
        "\n",
        "MissingValuesFilter(df_foxNY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3Ob6RA6pSTI",
        "outputId": "930e9ec2-29c2-4e1b-a36a-a61abfa7c626"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  res_values = method(rvalues)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This DataFrame does not contain missing values\n",
            "True True True True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking if Number of Occurrences is coherent\n",
        "def NumOccurrencesFilter(chunk):\n",
        "        size = len(chunk)\n",
        "        #To have a number of occurrences equal zero has no meaning, so here it checks if this data set \n",
        "        if chunk['numOccurrences'].all() == np.array(size*[0]).all():\n",
        "          print('Number of Occurrences impossible')\n",
        "        else :\n",
        "          print('Number of Occurences posible')\n",
        "\n",
        "NumOccurrencesFilter(df_foxNy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_69DHwVqjTQ",
        "outputId": "799e71a4-f66c-4525-b022-fc87e34180fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Occurences posible\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking if the Highest Probability Corresponds to the Autor of the quotation\n",
        "def ProbasFilter(chunk):\n",
        "        size = len(chunk)\n",
        "        if chunk['probas'].str[0].str[1].astype(float).all() < np.array(size*[0.8]).all():\n",
        "          print('Probability of Autors of quotation too low')\n",
        "        else :\n",
        "          print('Probability of Autors higher than 80%')\n",
        "\n",
        "ProbasFilter(df_foxNY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbDj4ud_qwHQ",
        "outputId": "9c91c934-d8ee-41db-b4bf-5de8e72814e2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability of Autors higher than 80%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking if the Autor is the one with the highest probability of having generated the quotation\n",
        "def ProbasFilter(chunk):  \n",
        "        if chunk['speaker'].all() != chunk['probas'].str[0].str[0].all():\n",
        "          print('The Autor does not correspond to the high probability Autor')\n",
        "        else :\n",
        "          print('The Autor has a high probability of having generated the quotation')\n",
        "\n",
        "ProbasFilter(df_foxNY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xc6ZQ0zkrJ8V",
        "outputId": "580848e9-8d93-448d-e8cf-9d2facd0762c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Autor has a high probability of having generated the quotation\n"
          ]
        }
      ]
    }
  ]
}