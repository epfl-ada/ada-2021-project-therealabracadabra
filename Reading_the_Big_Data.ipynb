{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reading_the_Big_Data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjRefaJPk7d4"
      },
      "source": [
        "# Project ADA: Part 1 Read Data and Load DataFrame for all the Years"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cv19i44Wpf6k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2b98e36-82d0-452f-f378-c63169790271"
      },
      "source": [
        "from google.colab import drive\n",
        "drive._mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfnFsmbCpqrs"
      },
      "source": [
        "!pip install pandas==1.0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIAN3Z0Sk7d_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84d3525c-9b3a-4f2a-f72d-3824f14c50d2"
      },
      "source": [
        "import seaborn as sns\n",
        "from IPython.display import display, HTML\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import bz2\n",
        "import json\n",
        "from urllib.parse import urlparse\n",
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "import os\n",
        "import glob\n",
        "import pickle"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rh99Atrck7eK"
      },
      "source": [
        "## Create Dataframe for each journal \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHobZi1sG6j6"
      },
      "source": [
        "def process_chunk(chunk, year, nb, df):\n",
        "    \n",
        "    df = chunk.drop(['qids', 'phase'], axis=1) #axis=1 for columns\n",
        "    \n",
        "    df['urls'] = df['urls'].astype('str') #Converting to string to be able to use str.contains \n",
        "    df_1 = df[df['urls'].str.contains('foxnews')] #Creating a DataFrame containing only foxnews\n",
        "    df_2 = df[df['urls'].str.contains('nytimes')]\n",
        "    df = pd.concat([df_1, df_2])\n",
        "\n",
        "    df.to_pickle('/content/drive/MyDrive/ADA_2021/' + str(nb) + '_' +  str(year) + '_' + 'FoxNYtimes.pkl')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPkOHIT7G8gT"
      },
      "source": [
        "years = [2015, 2016, 2017, 2018, 2019, 2020]\n",
        "nb = 1\n",
        "df = pd.DataFrame()\n",
        "for y in years:\n",
        "    nb = 1\n",
        "    for chunk in pd.read_json('/content/drive/MyDrive/Quotebank/quotes-' + str(y) + '.json.bz2', \n",
        "                              lines=True, compression='bz2', chunksize=500000):\n",
        "      \n",
        "      process_chunk(chunk, y, nb, df)\n",
        "      nb += 1"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXEmeZ4GHBJF"
      },
      "source": [
        "def read_yearly(y):\n",
        "    PATH = '/content/drive/MyDrive/ADA_2021/Fox_NY_' + str(y) + '/'\n",
        "    nb = 1\n",
        "    df2 = []\n",
        "    dirs = glob.glob(os.path.join(PATH, \"*.pkl\"))\n",
        "\n",
        "    for files in dirs:\n",
        "        df1 = pd.read_pickle(PATH + str(nb)+ '_' + str(y) + '_' + 'FoxNYtimes.pkl')\n",
        "        df2.append(df1)\n",
        "        nb += 1\n",
        "    return df2"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "years = [2015, 2016, 2017, 2018, 2019, 2020]\n",
        "df_foxNy = pd.DataFrame()\n",
        "\n",
        "for y in years:\n",
        "  df_foxNy = df_foxNy.append(pd.concat(read_yearly(y)))"
      ],
      "metadata": {
        "id": "qCkWHT2FINLA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_foxNy.sample(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "tx5f7LLhKDHK",
        "outputId": "a8147bfd-f7aa-4ee3-88ea-0717db36eda2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>quoteID</th>\n",
              "      <th>quotation</th>\n",
              "      <th>speaker</th>\n",
              "      <th>date</th>\n",
              "      <th>numOccurrences</th>\n",
              "      <th>probas</th>\n",
              "      <th>urls</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3708891</th>\n",
              "      <td>2019-12-31-004807</td>\n",
              "      <td>At the end of the day, we're in a blessed situ...</td>\n",
              "      <td>Kyle Van Noy</td>\n",
              "      <td>2019-12-31 00:00:00</td>\n",
              "      <td>3</td>\n",
              "      <td>[[Kyle Van Noy, 0.6539], [None, 0.3461]]</td>\n",
              "      <td>['http://www.foxnews.com/sports/patriots-kyle-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13001237</th>\n",
              "      <td>2018-08-05-003781</td>\n",
              "      <td>Astronomy is virtually as popular in Africa as...</td>\n",
              "      <td>David Baratoux</td>\n",
              "      <td>2018-08-05 08:47:46</td>\n",
              "      <td>1</td>\n",
              "      <td>[[David Baratoux, 0.8021], [None, 0.1862], [To...</td>\n",
              "      <td>['https://www.nytimes.com/2018/08/05/world/afr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13789361</th>\n",
              "      <td>2016-09-26-030062</td>\n",
              "      <td>He's the king of kings! Seeing him on the stre...</td>\n",
              "      <td>Maryse Narcisse</td>\n",
              "      <td>2016-09-26 21:03:22</td>\n",
              "      <td>25</td>\n",
              "      <td>[[Maryse Narcisse, 0.8254], [None, 0.1197], [J...</td>\n",
              "      <td>['http://www.seattletimes.com/nation-world/for...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    quoteID  ...                                               urls\n",
              "3708891   2019-12-31-004807  ...  ['http://www.foxnews.com/sports/patriots-kyle-...\n",
              "13001237  2018-08-05-003781  ...  ['https://www.nytimes.com/2018/08/05/world/afr...\n",
              "13789361  2016-09-26-030062  ...  ['http://www.seattletimes.com/nation-world/for...\n",
              "\n",
              "[3 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking if Filtering is Needed"
      ],
      "metadata": {
        "id": "cXZfOc6VpS9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Searching for Missing Values\n",
        "def MissingValuesFilter(chunk):\n",
        "        #Gives True as a result, if the lines where NaN are presents are empty \n",
        "        #(meaning there are no NaNs):\n",
        "        missing_nan = pd.DataFrame(np.where(chunk.isnull().any(axis=1))).empty\n",
        "        #Gives True as a result if the lignes and corresponding columns where \n",
        "        #zeros, '' and None are found are empty:\n",
        "        missing_zeros = pd.DataFrame(np.where(chunk==0)).empty \n",
        "        missing_space = pd.DataFrame(np.where(chunk=='')).empty\n",
        "        missing_none = pd.DataFrame(np.where(chunk==None)).empty\n",
        "        #missing_brackets = pd.DataFrame(np.where(chunk==[])).empty\n",
        "\n",
        "        print('This DataFrame does not contain missing values')\n",
        "        print(missing_nan, missing_zeros, missing_space, missing_none) \n",
        "\n",
        "MissingValuesFilter(df_foxNy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3Ob6RA6pSTI",
        "outputId": "9af1a6ef-19ee-473d-e5e5-25c71ffbae39"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  res_values = method(rvalues)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This DataFrame does not contain missing values\n",
            "True True True True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking if Number of Occurrences is coherent\n",
        "def NumOccurrencesFilter(chunk):\n",
        "        size = len(chunk)\n",
        "        #To have a number of occurrences equal zero has no meaning, so here it checks if this data set \n",
        "        if chunk['numOccurrences'].all() == np.array(size*[0]).all():\n",
        "          print('Number of Occurrences impossible')\n",
        "        else :\n",
        "          print('Number of Occurences posible')\n",
        "\n",
        "NumOccurrencesFilter(df_foxNy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_69DHwVqjTQ",
        "outputId": "799e71a4-f66c-4525-b022-fc87e34180fe"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Occurences posible\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking if the Highest Probability Corresponds to the Autor of the quotation\n",
        "def ProbasFilter(chunk):\n",
        "        size = len(chunk)\n",
        "        if chunk['probas'].str[0].str[1].astype(float).all() < np.array(size*[0.8]).all():\n",
        "          print('Probability of Autors of quotation too low')\n",
        "        else :\n",
        "          print('Probability of Autors higher than 80%')\n",
        "\n",
        "ProbasFilter(df_foxNy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbDj4ud_qwHQ",
        "outputId": "5b1b8595-63e0-49f0-a44a-f7d2fa1fe698"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability of Autors higher than 80%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking if the Autor is the one with the highest probability of having generated the quotation\n",
        "def ProbasFilter(chunk):  \n",
        "        if chunk['speaker'].all() != chunk['probas'].str[0].str[0].all():\n",
        "          print('The Autor does not correspond to the high probability Autor')\n",
        "        else :\n",
        "          print('The Autor has a high probability of having generated the quotation')\n",
        "\n",
        "ProbasFilter(df_foxNy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xc6ZQ0zkrJ8V",
        "outputId": "86afbc10-5826-4b28-ee59-721184e0d0bc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Autor has a high probability of having generated the quotation\n"
          ]
        }
      ]
    }
  ]
}