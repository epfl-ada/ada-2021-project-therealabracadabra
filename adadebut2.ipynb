{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bz2\n",
    "import json\n",
    "from urllib.parse import urlparse\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation d'un nouveau fichier avec une nouvelle colonne pour le domaine (cf colab)\n",
    "from tld import get_tld\n",
    "\n",
    "def get_domain(url):\n",
    "    res = get_tld(url, as_object=True)\n",
    "    return res.tld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation d'un fichier avec des colonnes en plus: le domaine et le nom du site internet du lien\n",
    "path_to_file = 'quotes-2017.json.bz2' \n",
    "path_to_out = '2017a.json.bz2'\n",
    "\n",
    "with bz2.open(path_to_file, 'rb') as s_file:\n",
    "    with bz2.open(path_to_out, 'wb') as d_file:\n",
    "        for instance in s_file:\n",
    "            instance = json.loads(instance) # loading a sample\n",
    "            urls = instance['urls'] # extracting list of links\n",
    "            domains = []\n",
    "            website = []\n",
    "            for url in urls:\n",
    "                tld = get_domain(url)\n",
    "                domains.append(tld)\n",
    "                net = urlparse(url)\n",
    "                neto=net.netloc\n",
    "                website.append(neto)\n",
    "            instance['domains'] = domains # updating the sample with domain name\n",
    "            instance['website'] = website\n",
    "            d_file.write((json.dumps(instance)+'\\n').encode('utf-8')) # writing in the new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation du dataframe à partir des 5 années avec les citations contenant un mot précis, ici immigrat\n",
    "path = os.getcwd()\n",
    "json_files = glob.glob(os.path.join(path, \"*.json.bz2\"))\n",
    "lista='quoteID', 'quotation', 'speaker', 'qids', 'date', 'numOccurrences','probas', 'urls', 'phase', 'domains', 'website'\n",
    "df2=pd.DataFrame(columns=lista) \n",
    "def process_chunk(chunk,df2):\n",
    "        immi=pd.DataFrame()\n",
    "        immi=chunk[chunk['quotation'].str.contains(\"immigrat\")]\n",
    "        df2 = df2.append(immi)\n",
    "        print(df2.shape)\n",
    "        return df2\n",
    "for f in json_files:      \n",
    "    for chunk in pd.read_json(f, lines=True, compression='bz2', chunksize=250000, encoding='utf-8'):\n",
    "        df2=process_chunk(chunk,df2)\n",
    "    print('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation du dataframe à partir des 5 années avec les citations d'un site en particulier\n",
    "path = os.getcwd()\n",
    "json_files = glob.glob(os.path.join(path, \"*.json.bz2\"))\n",
    "lista='quoteID', 'quotation', 'speaker', 'qids', 'date', 'numOccurrences','probas', 'urls', 'phase', 'domains', 'website'\n",
    "df3=pd.DataFrame(columns=lista) \n",
    "def process_chunk(chunk,df3):\n",
    "        chunk['website']=chunk['website'].astype('str')\n",
    "        journal=pd.DataFrame()\n",
    "        journal=chunk[chunk['website'].str.contains(\"www.foxnews.com\")]\n",
    "        df3 = df3.append(journal)\n",
    "        #print(df3.shape)\n",
    "        return df2\n",
    "for f in json_files:      \n",
    "    for chunk in pd.read_json(f, lines=True, compression='bz2', chunksize=25000, encoding='utf-8'):\n",
    "        df3=process_chunk(chunk,df3)\n",
    "    print('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3456, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['www.msn.com']</td>\n",
       "      <td>1202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['express.co.uk']</td>\n",
       "      <td>1184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['www.cheatsheet.com']</td>\n",
       "      <td>925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['www.bostonglobe.com']</td>\n",
       "      <td>769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['www.foxnews.com']</td>\n",
       "      <td>763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['timesofindia.indiatimes.com']</td>\n",
       "      <td>745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['www.dailystar.co.uk']</td>\n",
       "      <td>742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['www.telegraph.co.uk']</td>\n",
       "      <td>741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['indianexpress.com']</td>\n",
       "      <td>741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['www.thesun.co.uk']</td>\n",
       "      <td>730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['www.thehindu.com']</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['www.breitbart.com']</td>\n",
       "      <td>717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['www.forbes.com']</td>\n",
       "      <td>703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['www.mirror.co.uk']</td>\n",
       "      <td>642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['www.bbc.co.uk']</td>\n",
       "      <td>631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['www.washingtonexaminer.com']</td>\n",
       "      <td>596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['www.hindustantimes.com']</td>\n",
       "      <td>581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['www.theguardian.com']</td>\n",
       "      <td>544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['msn.com']</td>\n",
       "      <td>539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['www.latimes.com']</td>\n",
       "      <td>523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 website\n",
       "['www.msn.com']                     1202\n",
       "['express.co.uk']                   1184\n",
       "['www.cheatsheet.com']               925\n",
       "['www.bostonglobe.com']              769\n",
       "['www.foxnews.com']                  763\n",
       "['timesofindia.indiatimes.com']      745\n",
       "['www.dailystar.co.uk']              742\n",
       "['www.telegraph.co.uk']              741\n",
       "['indianexpress.com']                741\n",
       "['www.thesun.co.uk']                 730\n",
       "['www.thehindu.com']                 722\n",
       "['www.breitbart.com']                717\n",
       "['www.forbes.com']                   703\n",
       "['www.mirror.co.uk']                 642\n",
       "['www.bbc.co.uk']                    631\n",
       "['www.washingtonexaminer.com']       596\n",
       "['www.hindustantimes.com']           581\n",
       "['www.theguardian.com']              544\n",
       "['msn.com']                          539\n",
       "['www.latimes.com']                  523"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ici on voit que la colonne ajouter fonctionne\n",
    "lis=df2['website'].value_counts().to_frame()\n",
    "lis.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>None</td>\n",
       "      <td>84128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>President Donald Trump</td>\n",
       "      <td>1258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Bernie Sanders</td>\n",
       "      <td>595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Joe Biden</td>\n",
       "      <td>581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>President Trump</td>\n",
       "      <td>546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kirstjen Nielsen</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Jennifer Anderson</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>alan tongue</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Wes Welker</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Blake Hardwick</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62330 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        speaker\n",
       "None                      84128\n",
       "President Donald Trump     1258\n",
       "Bernie Sanders              595\n",
       "Joe Biden                   581\n",
       "President Trump             546\n",
       "...                         ...\n",
       "Kirstjen Nielsen              1\n",
       "Jennifer Anderson             1\n",
       "alan tongue                   1\n",
       "Wes Welker                    1\n",
       "Blake Hardwick                1\n",
       "\n",
       "[62330 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lis2=df3['speaker'].value_counts().to_frame()\n",
    "lis2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing the website column type to string\n",
    "df2['website']=df2['website'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation d'un dataframe pour quelques journaux\n",
    "fox=df2[df2['website'].str.contains(\"www.foxnews.com\")]\n",
    "ny=df2[df2['website'].str.contains(\"www.nytimes.com\")]\n",
    "brei=df2[df2['website'].str.contains(\"www.breitbart.com\")]\n",
    "cnn=df2[df2['website'].str.contains(\"cnn.com\")]\n",
    "guard=df2[df2['website'].str.contains(\"www.theguardian.com\")]\n",
    "slate=df2[df2['website'].str.contains(\"slate.com\")]\n",
    "buzz=df2[df2['website'].str.contains(\"buzzfeed.com\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "fox_quotes=fox['quotation']\n",
    "ny_quotes=ny['quotation']\n",
    "brei_quotes=brei['quotation']\n",
    "cnn_quotes=cnn['quotation']\n",
    "guard_quotes=guard['quotation']\n",
    "slate_quotes=slate['quotation']\n",
    "buzz_quotes=buzz['quotation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1787, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fox.shape\n",
    "ny.shape\n",
    "brei.shape\n",
    "cnn.shape\n",
    "guard.shape\n",
    "slate.shape\n",
    "buzz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11182372691661988 0.07998601007274761\n"
     ]
    }
   ],
   "source": [
    "#analyse de sentiments positif et negatif pour les journaux précédemment choisis\n",
    "pos=0\n",
    "neg=0\n",
    "average_pos=0\n",
    "average_neg=0\n",
    "for quotation in fox_quotes:\n",
    "    result=sia.polarity_scores(quotation)\n",
    "    pos=pos+result[\"pos\"]\n",
    "    neg=neg+result[\"neg\"]\n",
    "average_pos=pos/1787\n",
    "average_neg=neg/1787\n",
    "print(average_pos,average_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_quotes=df3['quotation']\n",
    "df3size=df3_quotes.shape(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09833275462962988 0.08480266203703696\n"
     ]
    }
   ],
   "source": [
    "pos=0\n",
    "neg=0\n",
    "average_pos=0\n",
    "average_neg=0\n",
    "for quotation in df3_quotes:\n",
    "    result=sia.polarity_scores(quotation)\n",
    "    pos=pos+result[\"pos\"]\n",
    "    neg=neg+result[\"neg\"]\n",
    "average_pos=pos/df3size\n",
    "average_neg=neg/df3size\n",
    "print(average_pos,average_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
